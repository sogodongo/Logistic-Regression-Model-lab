{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a Logistic Regression Model - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the last lesson you were given a broad overview of logistic regression. This included an introduction to two separate packages for creating logistic regression models. In this lab, you'll be investigating fitting logistic regressions with `statsmodels`. For your first foray into logistic regression, you are going to attempt to build a model that classifies whether an individual survived the [Titanic](https://www.kaggle.com/c/titanic/data) shipwreck or not (yes, it's a bit morbid).\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this lab you will: \n",
    "\n",
    "* Implement logistic regression with `statsmodels` \n",
    "* Interpret the statistical results associated with model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data\n",
    "\n",
    "Import the data stored in the file `'titanic.csv'` and print the first five rows of the DataFrame to check its contents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass   \n",
       "0              1         0       3  \\\n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp   \n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1  \\\n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Import the data\n",
    "df = pd.read_csv('titanic.csv')\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define independent and target variables\n",
    "\n",
    "Your target variable is in the column `'Survived'`. A `0` indicates that the passenger didn't survive the shipwreck. Print the total number of people who didn't survive the shipwreck. How many people survived?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of people who didn't survive the shipwreck: 549\n",
      "Total number of people who survived the shipwreck: 342\n"
     ]
    }
   ],
   "source": [
    "# Total number of people who didn't survive the shipwreck\n",
    "not_survived_count = df[df['Survived'] == 0]['Survived'].count()\n",
    "\n",
    "# Total number of people who survived the shipwreck\n",
    "survived_count = df[df['Survived'] == 1]['Survived'].count()\n",
    "\n",
    "print(\"Total number of people who didn't survive the shipwreck:\", not_survived_count)\n",
    "print(\"Total number of people who survived the shipwreck:\", survived_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only consider the columns specified in `relevant_columns` when building your model. The next step is to create dummy variables from categorical variables. Remember to drop the first level for each categorical column and make sure all the values are of type `float`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 8)\n"
     ]
    }
   ],
   "source": [
    "# Define the relevant columns\n",
    "relevant_columns = ['Pclass', 'Age', 'SibSp', 'Fare', 'Sex', 'Embarked', 'Survived']\n",
    "\n",
    "# Create the dummy variables\n",
    "dummy_dataframe = pd.get_dummies(df[relevant_columns], drop_first=True, dtype=float)\n",
    "\n",
    "# Check the shape of the dummy DataFrame\n",
    "print(dummy_dataframe.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice above that the DataFrame contains missing values? To keep things simple, simply delete all rows with missing values. \n",
    "\n",
    "> NOTE: You can use the [`.dropna()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html) method to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(714, 8)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values\n",
    "dummy_dataframe = dummy_dataframe.dropna()\n",
    "\n",
    "# Check the shape of the dummy DataFrame\n",
    "print(dummy_dataframe.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, assign the independent variables to `X` and the target variable to `y`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X and y\n",
    "y = dummy_dataframe['Survived']\n",
    "X = dummy_dataframe.drop(columns=['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "\n",
    "Now with everything in place, you can build a logistic regression model using `statsmodels` (make sure you create an intercept term as we showed in the previous lesson).  \n",
    "\n",
    "> Warning: Did you receive an error of the form \"LinAlgError: Singular matrix\"? This means that `statsmodels` was unable to fit the model due to certain linear algebra computational problems. Specifically, the matrix was not invertible due to not being full rank. In other words, there was a lot of redundant, superfluous data. Try removing some features from the model and running it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.443267\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               Survived   No. Observations:                  714\n",
      "Model:                          Logit   Df Residuals:                      706\n",
      "Method:                           MLE   Df Model:                            7\n",
      "Date:                Mon, 07 Aug 2023   Pseudo R-squ.:                  0.3437\n",
      "Time:                        18:58:35   Log-Likelihood:                -316.49\n",
      "converged:                       True   LL-Null:                       -482.26\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.103e-67\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          5.6503      0.633      8.921      0.000       4.409       6.892\n",
      "Pclass        -1.2118      0.163     -7.433      0.000      -1.531      -0.892\n",
      "Age           -0.0431      0.008     -5.250      0.000      -0.059      -0.027\n",
      "SibSp         -0.3806      0.125     -3.048      0.002      -0.625      -0.136\n",
      "Fare           0.0012      0.002      0.474      0.636      -0.004       0.006\n",
      "Sex_male      -2.6236      0.217    -12.081      0.000      -3.049      -2.198\n",
      "Embarked_Q    -0.8260      0.598     -1.381      0.167      -1.999       0.347\n",
      "Embarked_S    -0.4130      0.269     -1.533      0.125      -0.941       0.115\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Add an intercept term to X\n",
    "X_with_intercept = sm.add_constant(X)\n",
    "\n",
    "# Build the logistic regression model\n",
    "logit_model = sm.Logit(y, X_with_intercept)\n",
    "\n",
    "# Fit the model\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(result.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze results\n",
    "\n",
    "Generate the summary table for your model. Then, comment on the p-values associated with the various features you chose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value for the constant term (intercept) is 0.000, which means it is highly statistically significant. It indicates that the model's intercept is significantly different from zero, suggesting that it is an essential component of the model.\n",
    "\n",
    "For 'Pclass', 'Age', 'SibSp', and 'Sex_male', the p-values are less than 0.05 (i.e., 0.000), which means they are statistically significant. These variables have a significant impact on predicting the target variable 'Survived'.\n",
    "\n",
    "The 'Fare', 'Embarked_Q', and 'Embarked_S' variables have p-values greater than 0.05, indicating that they are not statistically significant in predicting 'Survived' at the 5% significance level.\n",
    "\n",
    " 'Pclass', 'Age', 'SibSp', and 'Sex_male' are statistically significant predictors of survival on the Titanic, while 'Fare', 'Embarked_Q', and 'Embarked_S' do not seem to have a significant impact on the outcome. You might consider removing the non-significant variables to simplify the model and improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up (Optional)\n",
    "\n",
    "Create a new model, this time only using those features you determined were influential based on your analysis of the results above. How does this model perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.445882\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               Survived   No. Observations:                  714\n",
      "Model:                          Logit   Df Residuals:                      709\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Mon, 07 Aug 2023   Pseudo R-squ.:                  0.3399\n",
      "Time:                        19:01:00   Log-Likelihood:                -318.36\n",
      "converged:                       True   LL-Null:                       -482.26\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.089e-69\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          5.6008      0.543     10.306      0.000       4.536       6.666\n",
      "Pclass        -1.3174      0.141     -9.350      0.000      -1.594      -1.041\n",
      "Age           -0.0444      0.008     -5.442      0.000      -0.060      -0.028\n",
      "SibSp         -0.3761      0.121     -3.106      0.002      -0.613      -0.139\n",
      "Sex_male      -2.6235      0.215    -12.229      0.000      -3.044      -2.203\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Select only the influential features\n",
    "influential_columns = ['Pclass', 'Age', 'SibSp', 'Sex_male']\n",
    "X_influential = X[influential_columns]\n",
    "\n",
    "# Add an intercept term to X_influential\n",
    "X_influential_with_intercept = sm.add_constant(X_influential)\n",
    "\n",
    "# Build the logistic regression model with influential features\n",
    "logit_model_influential = sm.Logit(y, X_influential_with_intercept)\n",
    "\n",
    "# Fit the model\n",
    "result_influential = logit_model_influential.fit()\n",
    "\n",
    "# Print the summary of the new model\n",
    "print(result_influential.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new logistic regression model, which includes only the influential features 'Pclass', 'Age', 'SibSp', and 'Sex_male', has the following performance:\n",
    "\n",
    "- **Pseudo R-squared:** The pseudo R-squared value of approximately 0.3399 indicates that the model explains about 33.99% of the variance in the target variable 'Survived'. This means that the model is moderately effective in explaining the variability in the survival outcome based on the selected features.\n",
    "\n",
    "- **Coefficients:** The coefficients represent the log-odds of the target variable 'Survived' for each unit change in the corresponding independent variable. For example, for every one unit increase in 'Pclass', the log-odds of survival decrease by approximately 1.3174, all else being equal.\n",
    "\n",
    "- **P-values:** All the p-values for the coefficients are less than 0.05 (i.e., 0.000), indicating that all the selected features ('Pclass', 'Age', 'SibSp', and 'Sex_male') are statistically significant in predicting 'Survived'. This confirms that the features included in the model are indeed influential and play a significant role in predicting the target variable.\n",
    "\n",
    "- **LLR p-value:** The LLR (Log-Likelihood Ratio) p-value is approximately 1.089e-69, which is extremely small. This indicates that the model significantly outperforms the null model (model with no predictors) and suggests that the selected features collectively provide a meaningful improvement in predicting 'Survived'.\n",
    "\n",
    "Thus,the new model with influential features seems to have a reasonably good performance in terms of statistical significance and pseudo R-squared. However, it's essential to remember that the model's predictive power may vary depending on the specific data and context. It's always a good practice to evaluate the model's performance on a separate test dataset and consider additional model evaluation metrics to ensure\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "Well done! In this lab, you practiced using `statsmodels` to build a logistic regression model. You then interpreted the results, building upon your previous stats knowledge, similar to linear regression. Continue on to take a look at building logistic regression models in Scikit-learn!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
